version: '3'

services:
  gpt-api:
    image: luchenyu/gpt-api:qwen2.5-vl
    runtime: nvidia
    shm_size: '80gb'
    ulimits:
      stack: 67108864
      memlock: -1
    ports:
      - "1042:8000"
    command: ["--model", "Benasd/Qwen2.5-VL-72B-Instruct-AWQ", "--max-model-len", "128000", "--tensor-parallel-size", "2", "--served-model-name", "Qwen2.5-VL-72B-Instruct", "--limit-mm-per-prompt", "image=256"]
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0,1" ]
              capabilities: [ gpu ]
